{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### André Campos da Silva\n",
    "\n",
    "\n",
    "### 08 de Janeiro, 2021\n",
    "\n",
    "### Projeto -  Spam Classifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Desenvolver um algoritmo em pyspark que seja capaz de determinar se uma mensagem é spam ou não, baseados em dados históricos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando pacotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import IDF\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer,StopWordsRemover\n",
    "from pyspark.ml.classification import NaiveBayes, NaiveBayesModel\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import udf, col, lower, regexp_replace,trim\n",
    "from nltk.stem.snowball import SnowballStemmer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregando os Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "RDDdataset = sc.textFile(\"Dados/sms_spam.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.PipelinedRDD"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['type,text',\n",
       " 'ham,Hope you are having a good week. Just checking in',\n",
       " 'ham,K..give back my thanks.',\n",
       " 'ham,Am also doing in cbe only. But have to pay.',\n",
       " 'spam,\"complimentary 4 STAR Ibiza Holiday or £10,000 cash needs your URGENT collection. 09066364349 NOW from Landline not to lose out! Box434SK38WP150PPM18+\"',\n",
       " 'spam,okmail: Dear Dave this is your final notice to collect your 4* Tenerife Holiday or #5000 CASH award! Call 09061743806 from landline. TCs SAE Box326 CW25WX 150ppm',\n",
       " 'ham,Aiya we discuss later lar... Pick u up at 4 is it?',\n",
       " 'ham,Are you this much buzy',\n",
       " 'ham,Please ask mummy to call father',\n",
       " 'spam,Marvel Mobile Play the official Ultimate Spider-man game (£4.50) on ur mobile right now. Text SPIDER to 83338 for the game & we ll send u a FREE 8Ball wallpaper']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDDdataset.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removo o cabeçalho \n",
    "cabecalho = RDDdataset.take(1)[0]\n",
    "RDDdataset = RDDdataset.filter(lambda line: line !=cabecalho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ham,Hope you are having a good week. Just checking in',\n",
       " 'ham,K..give back my thanks.',\n",
       " 'ham,Am also doing in cbe only. But have to pay.',\n",
       " 'spam,\"complimentary 4 STAR Ibiza Holiday or £10,000 cash needs your URGENT collection. 09066364349 NOW from Landline not to lose out! Box434SK38WP150PPM18+\"',\n",
       " 'spam,okmail: Dear Dave this is your final notice to collect your 4* Tenerife Holiday or #5000 CASH award! Call 09061743806 from landline. TCs SAE Box326 CW25WX 150ppm',\n",
       " 'ham,Aiya we discuss later lar... Pick u up at 4 is it?',\n",
       " 'ham,Are you this much buzy',\n",
       " 'ham,Please ask mummy to call father',\n",
       " 'spam,Marvel Mobile Play the official Ultimate Spider-man game (£4.50) on ur mobile right now. Text SPIDER to 83338 for the game & we ll send u a FREE 8Ball wallpaper',\n",
       " 'ham,\"fyi I\\'m at usf now, swing by the room whenever\"']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RDDdataset.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# formula para dividir o RDD em colunas e ja converte a label de caracterer para int. \n",
    "def transformlabel(RDD):\n",
    "    tolist = RDD.split(\",\")\n",
    "    label = 0.0 if tolist[0] == \"ham\" else 1.0\n",
    "    return [label, tolist[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 'Hope you are having a good week. Just checking in'],\n",
       " [0.0, 'K..give back my thanks.'],\n",
       " [0.0, 'Am also doing in cbe only. But have to pay.'],\n",
       " [1.0, '\"complimentary 4 STAR Ibiza Holiday or £10'],\n",
       " [1.0,\n",
       "  'okmail: Dear Dave this is your final notice to collect your 4* Tenerife Holiday or #5000 CASH award! Call 09061743806 from landline. TCs SAE Box326 CW25WX 150ppm'],\n",
       " [0.0, 'Aiya we discuss later lar... Pick u up at 4 is it?'],\n",
       " [0.0, 'Are you this much buzy'],\n",
       " [0.0, 'Please ask mummy to call father'],\n",
       " [1.0,\n",
       "  'Marvel Mobile Play the official Ultimate Spider-man game (£4.50) on ur mobile right now. Text SPIDER to 83338 for the game & we ll send u a FREE 8Ball wallpaper'],\n",
       " [0.0, '\"fyi I\\'m at usf now']]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplico a formula para o RDD \n",
    "RDDdataset2 = RDDdataset.map(transformlabel)\n",
    "RDDdataset2.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spark Session - Seção para usar a função de dataframe do spark\n",
    "spSession = SparkSession.builder.master(\"local\").appName(\"DSA-SparkMLLib\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crio um dataframe do spark com os dados tratados acuma. \n",
    "df_spam = spSession.createDataFrame(RDDdataset2, [\"label\", \"message\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  0.0|Hope you are havi...|\n",
      "|  0.0|K..give back my t...|\n",
      "|  0.0|Am also doing in ...|\n",
      "|  1.0|\"complimentary 4 ...|\n",
      "|  1.0|okmail: Dear Dave...|\n",
      "|  0.0|Aiya we discuss l...|\n",
      "|  0.0|Are you this much...|\n",
      "|  0.0|Please ask mummy ...|\n",
      "|  1.0|Marvel Mobile Pla...|\n",
      "|  0.0| \"fyi I'm at usf now|\n",
      "|  0.0|\"Sure thing big m...|\n",
      "|  0.0|   I anything lor...|\n",
      "|  0.0|    \"By march ending|\n",
      "|  0.0|           \"Hmm well|\n",
      "|  0.0|K I'll be sure to...|\n",
      "|  0.0|Ha ha cool cool c...|\n",
      "|  0.0|Darren was saying...|\n",
      "|  0.0|He dint tell anyt...|\n",
      "|  0.0|Up to u... u wan ...|\n",
      "|  1.0|\"U can WIN £100 o...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Imprimo as primeiras 10 linhas do dataframe. \n",
    "df_spam.select(\"label\", \"message\").show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converto todas as mesangem para minúsculo \n",
    "df_spam = df_spam.select('label', lower(col('message')).alias('message'))\n",
    "\n",
    "# Tiro os espaços\n",
    "df_spam = df_spam.select('label', trim(col('message')).alias('message'))\n",
    "\n",
    "# Limpeza a mesangem, tirando pontuações, números e etc.\n",
    "df_spam = df_spam.select('label',(regexp_replace('message','[^a-zA-Z\\\\s]', '')).alias('message'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  0.0|hope you are havi...|\n",
      "|  0.0|kgive back my thanks|\n",
      "|  0.0|am also doing in ...|\n",
      "|  1.0|complimentary  st...|\n",
      "|  1.0|okmail dear dave ...|\n",
      "|  0.0|aiya we discuss l...|\n",
      "|  0.0|are you this much...|\n",
      "|  0.0|please ask mummy ...|\n",
      "|  1.0|marvel mobile pla...|\n",
      "|  0.0|   fyi im at usf now|\n",
      "|  0.0|sure thing big ma...|\n",
      "|  0.0|      i anything lor|\n",
      "|  0.0|     by march ending|\n",
      "|  0.0|            hmm well|\n",
      "|  0.0|k ill be sure to ...|\n",
      "|  0.0|ha ha cool cool c...|\n",
      "|  0.0|darren was saying...|\n",
      "|  0.0|he dint tell anyt...|\n",
      "|  0.0|up to u u wan com...|\n",
      "|  1.0|u can win  of mus...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spam.select('*').show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenização da mesangem. \n",
    "tokenizer  = Tokenizer(inputCol='message', outputCol='messages_token')\n",
    "df_spam_token = tokenizer.transform(df_spam).select('label', 'messages_token')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Com a mensagem tokenizadas, realizamos a extração dos stopwords\n",
    "stopwords_remove = StopWordsRemover(inputCol ='messages_token', outputCol = 'messages')\n",
    "df_spam_none_stopwords = stopwords_remove.transform(df_spam_token).select('label', 'messages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ArrayType' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-174-0b096e6f5b10>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Limpeza das Words stemmings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstem_udf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mudf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokens\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mArrayType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mStringType\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdf_stem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstem_udf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf_spam_none_stopwords\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ArrayType' is not defined"
     ]
    }
   ],
   "source": [
    "# Limpeza das Words stemmings\n",
    "#stem = SnowballStemmer(language='english')\n",
    "#stem_udf = udf(lambda tokens: [stem.stem(token) for token in tokens], ArrayType(StringType()))\n",
    "#df_stem = stem_udf.transform(df_spam_none_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spam = df_spam_none_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|            messages|\n",
      "+--------------------+\n",
      "|[hope, good, week...|\n",
      "|[kgive, back, tha...|\n",
      "|    [also, cbe, pay]|\n",
      "|[complimentary, ,...|\n",
      "|[okmail, dear, da...|\n",
      "|[aiya, discuss, l...|\n",
      "|        [much, buzy]|\n",
      "|[please, ask, mum...|\n",
      "|[marvel, mobile, ...|\n",
      "|      [fyi, im, usf]|\n",
      "|[sure, thing, big...|\n",
      "|     [anything, lor]|\n",
      "|     [march, ending]|\n",
      "|         [hmm, well]|\n",
      "|[k, ill, sure, ge...|\n",
      "|[ha, ha, cool, co...|\n",
      "|[darren, saying, ...|\n",
      "|[dint, tell, anyt...|\n",
      "|[u, u, wan, come,...|\n",
      "|[u, win, , music,...|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_spam.select('messages').show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dos dados treino e teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de Treino e de Teste\n",
    "(data_train, data_test) = df_spam.randomSplit([0.7, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|             message|\n",
      "+-----+--------------------+\n",
      "|  0.0|                    |\n",
      "|  0.0|                    |\n",
      "|  0.0|                    |\n",
      "|  0.0|                    |\n",
      "|  0.0|  great loxahatch...|\n",
      "+-----+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data_train.select('*').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
